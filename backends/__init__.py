# Optional VLM backends (llama.cpp multimodal, etc.)
